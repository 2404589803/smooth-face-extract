{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdlfjx5zApmSLHsGPoTI52",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/smooth-face-extract/blob/main/notebook/%E6%B5%8B%E8%AF%95FaceDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ ] 导入视频\n",
        "- [ ] 选一个时间\n",
        "- [ ] 看看detection能不能跑"
      ],
      "metadata": {
        "id": "bAI78B8O2bZ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJuM6jqQ2Xy6",
        "outputId": "f359ff11-36a7-41c3-cb93-8613e413cf98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/SD/exp0226"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5IlIizX2z--",
        "outputId": "38fd83a4-703e-41f0-8d3c-24ee42167b85"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "expression_example.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_video = \"/content/drive/MyDrive/SD/exp0226/expression_example.mp4\"\n",
        "target_folder = \"/content/\"\n",
        "\n",
        "import shutil\n",
        "\n",
        "shutil.copy(input_video, target_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dYsUgo553Ahw",
        "outputId": "9cf18b03-dafd-4153-935b-af73cc2aeaad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/expression_example.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf /content/smooth-face-extract\n",
        "!git clone https://github.com/LC1332/smooth-face-extract\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb5Xen4j3Lrf",
        "outputId": "f73de688-4e9d-425a-8172-ea3b647299be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'smooth-face-extract'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 48 (delta 23), reused 3 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (48/48), 23.89 KiB | 3.98 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/smooth-face-extract/Face_detection_src\n",
        "!ls\n",
        "!mkdir face_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6zuNEfK4HPn",
        "outputId": "d0bdf96f-2801-43cc-dd8d-6caf8f2b175d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/smooth-face-extract/Face_detection_src\n",
            "combine_img_to_video.py        FaceDetection_MAFilter.py  __init__\n",
            "FaceDetection_KalmanFilter.py  FaceDetection.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvhrLE7K4Vtd",
        "outputId": "1a23eef2-0e65-4a61-ae67-57821c267063"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.8/34.8 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf face_images\n",
        "\n",
        "!rm -rf output"
      ],
      "metadata": {
        "id": "WC6Btfpz4p6O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python FaceDetection_KalmanFilter.py --input_video_name /content/expression_example.mp4 \\\n",
        "    --start_time 00:43:55 \\\n",
        "    --end_time 00:44:04 \\\n",
        "    --maxcenter_speed 30\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRPlvLhG3WnH",
        "outputId": "667fce82-4f2f-40eb-a789-088c66f9142d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-02-29 01:18:30.573324: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-29 01:18:30.573445: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-29 01:18:30.576160: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-29 01:18:30.593755: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-02-29 01:18:33.181182: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ErpQtfdz4m88"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "读取视频的一个frame\n",
        "\n",
        "获得fps\n",
        "\n",
        "获得start和end time\n"
      ],
      "metadata": {
        "id": "eMzJQlTmdv1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_frame_no(time_str, fps):\n",
        "    h, m, s = map(int, time_str.split(\":\"))\n",
        "    return int((h * 3600 + m * 60 + s) * fps)"
      ],
      "metadata": {
        "id": "fbviU6ZHeHq1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_video_name = \"/content/expression_example.mp4\"\n",
        "start_time = \"00:43:55\"\n",
        "end_time = \"00:44:04\"\n",
        "\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(input_video_name)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)"
      ],
      "metadata": {
        "id": "x_Ryx8gidwwH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_frame_no = get_frame_no(start_time, fps)\n",
        "end_frame_no = get_frame_no(end_time, fps)"
      ],
      "metadata": {
        "id": "_bBiFJwbeFLn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "\n",
        "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
        "\n"
      ],
      "metadata": {
        "id": "M2ZoZwjUeVbi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(face_detection))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_SC6wX2eiGQ",
        "outputId": "2fd36348-bf98-4c47-810d-b045ee8e7171"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_get_packet_content', '_graph', '_graph_outputs', '_initialize_graph_interface', '_input_side_packets', '_input_stream_type_info', '_make_packet', '_modify_calculator_options', '_output_stream_type_info', '_set_extension', '_side_input_type_info', '_simulated_timestamp', 'close', 'create_graph_options', 'process', 'reset']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_get_packet_content', '_graph', '_graph_outputs', '_initialize_graph_interface', '_input_side_packets', '_input_stream_type_info', '_make_packet', '_modify_calculator_options', '_output_stream_type_info', '_set_extension', '_side_input_type_info', '_simulated_timestamp', 'close', 'create_graph_options', 'process', 'reset']"
      ],
      "metadata": {
        "id": "f_tk0P0egiNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O detector.tflite -q https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite"
      ],
      "metadata": {
        "id": "WidaQZCqipBm"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "\n",
        "BaseOptions = mp.tasks.BaseOptions\n",
        "FaceDetector = mp.tasks.vision.FaceDetector\n",
        "FaceDetectorOptions = mp.tasks.vision.FaceDetectorOptions\n",
        "VisionRunningMode = mp.tasks.vision.RunningMode\n",
        "\n",
        "# Create a face detector instance with the video mode:\n",
        "options = FaceDetectorOptions(\n",
        "    base_options= BaseOptions( model_asset_path='detector.tflite'),\n",
        "    running_mode=VisionRunningMode.VIDEO,\n",
        "    min_detection_confidence=0.5)\n",
        "\n",
        "face_detection = FaceDetector.create_from_options(options)\n"
      ],
      "metadata": {
        "id": "57bgqFuaf6ib"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nt(options)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDe5GPQ1f6ca",
        "outputId": "b1c8ffd9-45a4-45de-9ffa-faadca303a43"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FaceDetectorOptions(base_options=BaseOptions(model_asset_path='/content/model.task', model_asset_buffer=None, delegate=None), running_mode=<VisionTaskRunningMode.VIDEO: 'VIDEO'>, min_detection_confidence=0.5, min_suppression_threshold=0.3, result_callback=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jl7RG6Jyh02_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}